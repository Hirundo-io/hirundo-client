{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hirundo-io/hirundo-python-sdk/blob/clnt-9-add-jupyter-notebooks-to-github/notebooks/Create_BDD100k_dataset_AWS_S3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_LpV5xrmW9e"
      },
      "source": [
        "# How to create a Hirundo dataset (AWS S3)\n",
        "\n",
        "--\n",
        "\n",
        "0. Install `pandas` and `tqdm`, set the AWS environment variables from the colab secrets and set `bucket_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTKCTNM4Hz44",
        "outputId": "9bd6a9dd-5809-40aa-ef6d-23f3168c255d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas tqdm\n",
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = userdata.get(\"AWS_ACCESS_KEY_RW\")\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = userdata.get(\"AWS_SECRET_KEY_RW\")\n",
        "os.environ[\"AWS_SESSION_TOKEN\"] = userdata.get(\"AWS_SESSION_TOKEN_RW\")\n",
        "os.environ[\"AWS_DEFAULT_REGION\"] = userdata.get(\"AWS_DEFAULT_REGION\")\n",
        "\n",
        "bucket_name = \"hirundo-test-bucket\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSO4NhimHw9C"
      },
      "source": [
        "1. Import `tempfile` to create a temporary directory, and import `requests`, `zipfile`, `io`, & `hashlib` to download and unzip BDD100k."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oPoIGAlcIUD1"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "import io\n",
        "import tempfile\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "import requests\n",
        "\n",
        "bdd100k_temp_dir = tempfile.TemporaryDirectory()\n",
        "bdd100k_temp_dir_name = bdd100k_temp_dir.name\n",
        "bdd100k_temp_dir_path = Path(bdd100k_temp_dir_name)\n",
        "\n",
        "\n",
        "def get_zip_check_md5_and_unzip(url: str, target_folder: str, check_md5=False):\n",
        "    data_request_result = requests.get(\n",
        "        url,\n",
        "        timeout=900.0,\n",
        "    )\n",
        "    data_bytes = data_request_result.content\n",
        "    if check_md5:\n",
        "        data_verify_md5 = requests.get(\n",
        "            f\"{url}.md5\",\n",
        "            timeout=30.0,\n",
        "        ).text.split(\" \")[0]\n",
        "        data_actual_md5 = hashlib.md5(data_bytes).hexdigest()\n",
        "        if data_verify_md5 != data_actual_md5:\n",
        "            raise ValueError(\n",
        "                f\"ZIP download failed. {data_verify_md5} != {data_actual_md5}. Try again\"\n",
        "            )\n",
        "    data_zip = zipfile.ZipFile(io.BytesIO(data_bytes))\n",
        "    data_zip.extractall(target_folder)\n",
        "\n",
        "\n",
        "get_zip_check_md5_and_unzip(\n",
        "    \"https://dl.cv.ethz.ch/bdd100k/data/100k_images_val.zip\",\n",
        "    bdd100k_temp_dir_name,\n",
        "    check_md5=True,\n",
        ")\n",
        "get_zip_check_md5_and_unzip(\n",
        "    \"https://dl.cv.ethz.ch/bdd100k/data/bdd100k_det_20_labels_trainval.zip\",\n",
        "    bdd100k_temp_dir_name,\n",
        ")\n",
        "#  ⬆️ as per: https://doc.bdd100k.com/download.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCbIfyb0SEOL"
      },
      "source": [
        "2. Import `Path` from `pathlib`, `json`, `pandas` and `tqdm` to create dataset DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kg_jEsE3RGs2"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye7piGx8SLJ9"
      },
      "source": [
        "3. Create Hirundo CSV for dataset, with `tqdm` to track progress, from source JSON file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Rz6zqU1pHvIT",
        "outputId": "59573cae-f1dc-470f-f402-2365cb506f97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading BDD100K validation set: 100%|██████████| 10000/10000 [00:00<00:00, 29104.51it/s]\n"
          ]
        }
      ],
      "source": [
        "df_rows = []\n",
        "\n",
        "bdd100k_hirundo_temp_dir = tempfile.TemporaryDirectory()\n",
        "bdd100k_hirundo_temp_dir_name = bdd100k_hirundo_temp_dir.name\n",
        "\n",
        "bdd100k_hirundo_temp_dir_path = Path(bdd100k_hirundo_temp_dir_name)\n",
        "with open(bdd100k_temp_dir_path / \"bdd100k/labels/det_20/det_val.json\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "for sample in tqdm(data, total=len(data), desc=\"Loading BDD100K validation set\"):\n",
        "    if sample[\"labels\"] is not None:\n",
        "        for i, label in enumerate(sample[\"labels\"]):\n",
        "            df_rows.append(\n",
        "                {\n",
        "                    \"image_path\": str(\n",
        "                        Path(\"/bdd100k/images/100k/val/\") / sample[\"name\"]\n",
        "                    ),\n",
        "                    \"bbox_id\": str(\n",
        "                        i\n",
        "                    ),  # Box index in image used for box ID (since no unique ID is provided)\n",
        "                    \"class_name\": label[\"category\"],\n",
        "                    \"xmin\": int(label[\"box2d\"][\"x1\"]),\n",
        "                    \"ymin\": int(label[\"box2d\"][\"y1\"]),\n",
        "                    \"xmax\": int(label[\"box2d\"][\"x2\"]),\n",
        "                    \"ymax\": int(label[\"box2d\"][\"y2\"]),\n",
        "                }\n",
        "            )\n",
        "\n",
        "df = pd.DataFrame(df_rows)\n",
        "df.to_csv(bdd100k_hirundo_temp_dir_path / \"bdd100k.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxQCfz7FR_z_"
      },
      "source": [
        "4. Create a ZIP of the dataset to upload to S3.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q9jw8DkwSpak",
        "outputId": "651189b1-8370-4cfe-8864-8161a26359fe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/bdd100k_val_hirundo.zip'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "relative_path = \"bdd100k/images\"\n",
        "(bdd100k_hirundo_temp_dir_path / \"bdd100k\").mkdir()\n",
        "shutil.copytree(\n",
        "    bdd100k_temp_dir_path / relative_path, bdd100k_hirundo_temp_dir_path / relative_path\n",
        ")\n",
        "\n",
        "bdd_zip = shutil.make_archive(\n",
        "    base_name=\"bdd100k_val_hirundo\",\n",
        "    format=\"zip\",\n",
        "    root_dir=bdd100k_hirundo_temp_dir_path,\n",
        ")\n",
        "bdd_zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAQ6dC-OSptk"
      },
      "source": [
        "5. Upload ZIP to AWS S3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Hh2yPkITBtL",
        "outputId": "cb70664e-db36-4630-d289-85b78f687bb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: awscli in /usr/local/lib/python3.10/dist-packages (1.33.26)\n",
            "Requirement already satisfied: botocore==1.34.144 in /usr/local/lib/python3.10/dist-packages (from awscli) (1.34.144)\n",
            "Requirement already satisfied: docutils<0.17,>=0.10 in /usr/local/lib/python3.10/dist-packages (from awscli) (0.16)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from awscli) (0.10.2)\n",
            "Requirement already satisfied: PyYAML<6.1,>=3.10 in /usr/local/lib/python3.10/dist-packages (from awscli) (6.0.1)\n",
            "Requirement already satisfied: colorama<0.4.7,>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from awscli) (0.4.6)\n",
            "Requirement already satisfied: rsa<4.8,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from awscli) (4.7.2)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from botocore==1.34.144->awscli) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore==1.34.144->awscli) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore==1.34.144->awscli) (2.0.7)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.34.144->awscli) (1.16.0)\n",
            "upload: ./bdd100k_val_hirundo.zip to s3://hirundo-test-bucket/bdd100k_val_hirundo.zip\n"
          ]
        }
      ],
      "source": [
        "bdd_zip_filename = Path(bdd_zip).name\n",
        "%pip install awscli\n",
        "\n",
        "!aws s3 cp $bdd_zip s3://$bucket_name/$bdd_zip_filename"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfa6i34pSvBO"
      },
      "source": [
        "6. Get `BDD100k` class list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zxQi_Z8iSutj",
        "outputId": "b5fb43c6-d0e1-4351-88ba-9c455c5559a2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"traffic sign\", \"traffic light\", \"car\", \"rider\", \"motorcycle\", \"pedestrian\", \"bus\", \"truck\", \"bicycle\", \"other vehicle\", \"train\", \"trailer\", \"other person\"'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bdd100k_classes = df[\"label\"].unique()\n",
        "'\"' + '\", \"'.join(bdd100k_classes) + '\"'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TdFBuBqSnTt"
      },
      "source": [
        "7. Cleanup dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2RcNa_oHR_QP"
      },
      "outputs": [],
      "source": [
        "bdd100k_temp_dir.cleanup()\n",
        "bdd100k_hirundo_temp_dir.cleanup()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNNupmDZ0MWobt5ZyrWZynw",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
