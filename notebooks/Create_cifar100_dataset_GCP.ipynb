{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPxdSYkmColOMCOR0/KLCP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hirundo-io/hirundo-client/blob/clnt-9-add-jupyter-notebooks-to-github/notebooks/Create_cifar100_dataset_GCP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to create a Hirundo dataset (GCP Storage Bucket)\n",
        "\n",
        "--\n",
        "\n",
        "0. Install `torchvision` and `pandas`, set the `GCP_CREDENTIALS` environment variable and set `bucket_name`."
      ],
      "metadata": {
        "id": "g_LpV5xrmW9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchvision pandas\n",
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = userdata.get(\"GCP_CREDENTIALS_RW\")\n",
        "\n",
        "bucket_name = \"cifar100bucket\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oWfqvbjqnGPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import `tempfile` to create a temporary directory & `CIFAR100` from `torchvision.datasets` to download the dataset."
      ],
      "metadata": {
        "id": "Pu4f2_pMoEFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "\n",
        "from torchvision.datasets import CIFAR100\n",
        "\n",
        "temp_dir = tempfile.TemporaryDirectory()\n",
        "temp_dir_name = temp_dir.name\n",
        "cifar100 = CIFAR100(temp_dir_name, download=True)"
      ],
      "metadata": {
        "id": "Pb4ek3PmmvFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Import `Path` from `pathlib` and `pandas` to create `DataFrame`."
      ],
      "metadata": {
        "id": "Zf1Z0mBznX0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "I208k_ApnJyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Create `DataFrame`."
      ],
      "metadata": {
        "id": "wcqwrgRDnfUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dir_dataset_path = Path(temp_dir_name) / \"dataset\"\n",
        "temp_dir_dataset_path.mkdir()\n",
        "img_dir = temp_dir_dataset_path / \"images\"\n",
        "img_dir.mkdir()\n",
        "\n",
        "csv = pd.DataFrame(columns=[\"image_path\", \"label\"], index=range(len(cifar100)))\n",
        "for i, item in enumerate(cifar100):\n",
        "    image, target = item\n",
        "    image_path = img_dir / f\"{i}.png\"\n",
        "    csv.loc[i] = {\n",
        "        \"image_path\": image_path.relative_to(temp_dir_dataset_path),\n",
        "        \"label\": cifar100.classes[target],\n",
        "    }\n",
        "    image.save(image_path)\n",
        "\n",
        "csv.to_csv(\n",
        "    temp_dir_dataset_path / \"cifar100.csv\"\n",
        ")"
      ],
      "metadata": {
        "id": "7sh-oMrlnelv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Upload the CSV and images to GCP Storage Bucket."
      ],
      "metadata": {
        "id": "NjizJW8Xon3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil -m rsync $img_dir gs://$bucket_name/$img_dir\n",
        "!gsutil cp $temp_dir_dataset_path/cifar100.csv gs://$bucket_name/cifar100.csv"
      ],
      "metadata": {
        "id": "l3aI30_Kor0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Get `cifar100` class list."
      ],
      "metadata": {
        "id": "UkmpY6SEpx7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'\"' + '\", \"'.join(cifar100.classes) + '\"'"
      ],
      "metadata": {
        "id": "qT1L3aYVpwm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Cleanup the temporary folder."
      ],
      "metadata": {
        "id": "gyUm2gtLosbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dir.cleanup()"
      ],
      "metadata": {
        "id": "gJdn1BC3nsFq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}