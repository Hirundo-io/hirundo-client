{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blewis/Programming/hirundo-client/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "5 validation errors for DataOptimizationDatasetOut\nlabeling_type\n  Field required [type=missing, input_value={'name': 'Keymakr data4 -...1500, 'path': '/data4'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing\nstorage_integration\n  Field required [type=missing, input_value={'name': 'Keymakr data4 -...1500, 'path': '/data4'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing\ndata_root_url\n  Field required [type=missing, input_value={'name': 'Keymakr data4 -...1500, 'path': '/data4'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing\nlabeling_info\n  Field required [type=missing, input_value={'name': 'Keymakr data4 -...1500, 'path': '/data4'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing\nstatus\n  Field required [type=missing, input_value={'name': 'Keymakr data4 -...1500, 'path': '/data4'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m\n\u001b[1;32m     15\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     17\u001b[0m unique_id \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUNIQUE_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m run_ids \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 20\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mrun_id \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[43mOptimizationDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[1;32m     21\u001b[0m ]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run_id \u001b[38;5;129;01min\u001b[39;00m run_ids:\n\u001b[1;32m     23\u001b[0m     OptimizationDataset\u001b[38;5;241m.\u001b[39mcancel_by_id(run_id)\n",
      "File \u001b[0;32m~/Programming/hirundo-client/hirundo/dataset_optimization.py:298\u001b[0m, in \u001b[0;36mOptimizationDataset.list\u001b[0;34m(organization_id)\u001b[0m\n\u001b[1;32m    296\u001b[0m raise_for_status_with_reason(response)\n\u001b[1;32m    297\u001b[0m datasets \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m--> 298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    299\u001b[0m     DataOptimizationDatasetOut(\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mds,\n\u001b[1;32m    301\u001b[0m     )\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets\n\u001b[1;32m    303\u001b[0m ]\n",
      "File \u001b[0;32m~/Programming/hirundo-client/hirundo/dataset_optimization.py:299\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    296\u001b[0m raise_for_status_with_reason(response)\n\u001b[1;32m    297\u001b[0m datasets \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 299\u001b[0m     \u001b[43mDataOptimizationDatasetOut\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets\n\u001b[1;32m    303\u001b[0m ]\n",
      "File \u001b[0;32m~/Programming/hirundo-client/.venv/lib/python3.9/site-packages/pydantic/main.py:193\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    192\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 5 validation errors for DataOptimizationDatasetOut\nlabeling_type\n  Field required [type=missing, input_value={'name': 'Keymakr data4 -...1500, 'path': '/data4'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing\nstorage_integration\n  Field required [type=missing, input_value={'name': 'Keymakr data4 -...1500, 'path': '/data4'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing\ndata_root_url\n  Field required [type=missing, input_value={'name': 'Keymakr data4 -...1500, 'path': '/data4'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing\nlabeling_info\n  Field required [type=missing, input_value={'name': 'Keymakr data4 -...1500, 'path': '/data4'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing\nstatus\n  Field required [type=missing, input_value={'name': 'Keymakr data4 -...1500, 'path': '/data4'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from hirundo import (\n",
    "    GitRepo,\n",
    "    HirundoCSV,\n",
    "    LabelingType,\n",
    "    OptimizationDataset,\n",
    "    StorageConfig,\n",
    "    StorageGit,\n",
    "    StorageTypes,\n",
    ")\n",
    "from hirundo.git import GitPlainAuthBase\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "unique_id = os.getenv(\"UNIQUE_ID\", \"\").replace(\".\", \"-\").replace(\"/\", \"-\")\n",
    "\n",
    "run_ids = [run.run_id for run in OptimizationDataset.list_runs() if run.run_id]\n",
    "for run_id in run_ids:\n",
    "    OptimizationDataset.cancel_by_id(run_id)\n",
    "dataset_ids = [dataset.id for dataset in OptimizationDataset.list_datasets()]\n",
    "for dataset_id in dataset_ids:\n",
    "    OptimizationDataset.delete_by_id(dataset_id)\n",
    "storage_ids = [storage_config.id for storage_config in StorageConfig.list()]\n",
    "for storage_id in storage_ids:\n",
    "    StorageConfig.delete_by_id(storage_id)\n",
    "git_repo_ids = [git_repo.id for git_repo in GitRepo.list()]\n",
    "for git_repo_id in git_repo_ids:\n",
    "    GitRepo.delete_by_id(git_repo_id)\n",
    "\n",
    "test_storage_git = StorageGit(\n",
    "    repo=GitRepo(\n",
    "        name=f\"STT-RoboShaul-dataset{unique_id}\",\n",
    "        repository_url=\"https://huggingface.co/datasets/hirundo-io/RoboShaul\",\n",
    "        plain_auth=GitPlainAuthBase(\n",
    "            username=\"blewis-hir\",\n",
    "            password=os.environ[\"HUGGINGFACE_ACCESS_TOKEN\"],\n",
    "        ),\n",
    "    ),\n",
    "    branch=\"main\",\n",
    ")\n",
    "test_dataset = OptimizationDataset(\n",
    "    name=f\"TEST-STT-RoboShaul-dataset{unique_id}\",\n",
    "    labeling_type=LabelingType.SPEECH_TO_TEXT,\n",
    "    language=\"he\",\n",
    "    storage_config=StorageConfig(\n",
    "        name=f\"STT-RoboShaul-dataset{unique_id}\",\n",
    "        type=StorageTypes.GIT,\n",
    "        git=test_storage_git,\n",
    "    ),\n",
    "    data_root_url=test_storage_git.get_url(\"/wavs\"),\n",
    "    labeling_info=HirundoCSV(\n",
    "        csv_url=test_storage_git.get_url(\"/meta.csv\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "test_dataset.run_optimization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_dataset.check_run()\n",
    "results.suspects.to_csv(\"he-on-prem-audio-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
